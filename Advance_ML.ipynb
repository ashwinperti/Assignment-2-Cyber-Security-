{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advance_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mMzX4oO1NHAV",
        "fBQHBGxeNHAX",
        "zeA_UAbINHAX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinperti/Assignment-2-Cyber-Security-/blob/master/Advance_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PQdLQzDNHAL"
      },
      "source": [
        "# FDP on “Data Science for IoT” from 21st-25th June 2021.\n",
        "\n",
        "**Instructor** : [Dr. Chandra Prakash , NIT Delhi]\n",
        "\n",
        " \n",
        "* DATE: 23-June-2021\n",
        "\n",
        "\n",
        "\n",
        "#  Advance Machine Learning \n",
        "\n",
        "\n",
        "- Perceptron \n",
        "- Neural Network \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyGt6gPnNHAM"
      },
      "source": [
        "# Perceptron\n",
        "- A perceptron is a neural network without any hidden layer. A perceptron only has an input layer and an output layer.\n",
        " \n",
        " <img src=\"p1.png\" width=\"600\">  <img src=\"Perceptron1.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXBnCMHVybJS"
      },
      "source": [
        "#  Multlayer  Artifical Neural Net  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry46oD_PNHAN"
      },
      "source": [
        "### Limitations of Single layer Neural Networks\n",
        " \n",
        "- They can only represent a limited set of functions. If we have been training a model that uses complicated functions (which is the general case), then using a single layer neural network can lead to low accuracy in our prediction rate.\n",
        "- They can only predict linearly separable data. If we have non-linear data, then training our single-layer neural network will lead to low accuracy in our prediction rate.\n",
        "- Decision boundaries for single-layer neural networks must be in the hyperplane, which means that if our data distributes in 3 dimensions, then our decision boundary must be in 2 dimensions.\n",
        "\n",
        "\n",
        "![](nl.png)\n",
        "\n",
        "To overcome such limitations, we use hidden layers in our neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uSrLj-mNHAO"
      },
      "source": [
        "Advantages of multilayer neural networks:\n",
        "- They construct more extensive networks by considering layers of processing units.\n",
        "- They can be used to classify non-linearly separable data.\n",
        "- Multilayer neural networks are more reliable compared to single-layer neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cd6kHxNNHAO"
      },
      "source": [
        "### How to select several neurons in a hidden layer?\n",
        "- The number of hidden nodes should be less than twice the size of the nodes in the input layer.\n",
        "\n",
        "- The number of hidden nodes should be 2/3 the size of input nodes, plus the size of the output node.\n",
        "\n",
        "- The number of hidden nodes should be between the size of input nodes and output nodes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzq7rDzMNHAP"
      },
      "source": [
        "### How many weight values do we need?\n",
        "- For a hidden layer: Number of inputs * No. of hidden layer nodes\n",
        "- For an output layer: Number of hidden layer nodes * No. of outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuVHA9g6NHAP"
      },
      "source": [
        "### The General Structure of an Artificial Neural Network (ANN):\n",
        " \n",
        " <img src=\"mlp.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTGuj1ELNHAP"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_juOEO-NHAQ"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    %tensorflow_version 2.x\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "    \n",
        "# Print your name . \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIhjbn-NO8I2"
      },
      "source": [
        "# Only require for google colab \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/'My Drive/Colab_work/HAR'/\"FDP\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6KjxgkzNHAQ"
      },
      "source": [
        "## PART 1.1:  Neural Network from scratch \n",
        "\n",
        "CASE STUDY 1: Predicting Virus Contraction with a Artifical Neural Net  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecQCkBFgNHAQ"
      },
      "source": [
        "\n",
        "Summarizing an Artificial Neural Network:\n",
        "1. Take inputs\n",
        "2. Add bias (if required)\n",
        "3. Assign random weights to input features\n",
        "4. Run the code for training.\n",
        "5. Find the error in prediction.\n",
        "6. Update the weight by gradient descent algorithm.\n",
        "7. Repeat the training phase with updated weights.\n",
        "8. Make predictions.\n",
        "\n",
        "\n",
        " <img src=\"data_1.png\" width=\"400\">\n",
        "  <img src=\"perceptron.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy3e5bFPNHAR"
      },
      "source": [
        "# Import required libraries :\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoNBn8mPNHAR"
      },
      "source": [
        "# Define input features :\n",
        "\n",
        "input_features = # WRITE YOUR CODE HERE \n",
        "\n",
        "\n",
        "\n",
        "print (input_features.shape)\n",
        "print (input_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc4OSEy_NHAR"
      },
      "source": [
        "# Define target output :\n",
        "\n",
        "target_output = # WRITE YOUR CODE HERE \n",
        "\n",
        "\n",
        "# Reshaping our target output into vector :\n",
        "target_output = target_output.reshape(8,1)\n",
        "print(target_output.shape)\n",
        "print (target_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4YXzH76NHAS"
      },
      "source": [
        "# Define weights :\n",
        "\n",
        "weights =  # WRITE YOUR CODE HERE \n",
        "\n",
        "print(weights.shape)\n",
        "print (weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apaEb6ALNHAS"
      },
      "source": [
        "# Bias weight :\n",
        "bias =  # WRITE YOUR CODE HERE\n",
        "# Learning Rate :\n",
        "lr = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wzMTgFNHAS"
      },
      "source": [
        "# Sigmoid function :\n",
        "def sigmoid(x):\n",
        "    return # WRITE YOUR CODE HERE \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmTfGWLcNHAT"
      },
      "source": [
        "# Derivative of sigmoid function :\n",
        "# Hint : https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e\n",
        "  # The use of derivatives in neural networks is for the training process called backpropagation. \n",
        "  # This technique uses gradient descent in order to find an optimal set of model parameters in order to minimize   \n",
        "  # a loss function. \n",
        "    #We use the derivative of a sigmoid because that is the activation that  individual neurons  are using.\n",
        "\n",
        "\n",
        "def sigmoid_der(x):\n",
        "   \n",
        "    return # WRITE YOUR CODE HERE \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6O6FRLYNHAT"
      },
      "source": [
        "# Main logic for neural network :\n",
        "# Running our code 10000 times :\n",
        "\n",
        "for epoch in range(# WRITE YOUR CODE HERE):\n",
        " inputs = input_features\n",
        "    \n",
        " #Feedforward input :\n",
        " pred_in = # WRITE YOUR CODE HERE (Summation value )\n",
        "    \n",
        " #Feedforward output :\n",
        "    \n",
        " pred_out = # WRITE YOUR CODE HERE\n",
        " \n",
        " #Backpropogation \n",
        " #Calculating error\n",
        "    \n",
        " error = # WRITE YOUR CODE HERE\n",
        " \n",
        " #Going with the formula :\n",
        " x = error.sum()\n",
        " print(x)\n",
        " \n",
        " #Calculating derivative :\n",
        " dcost_dpred = error\n",
        " dpred_dz = sigmoid_der(pred_out)\n",
        " \n",
        " #Multiplying individual derivatives :\n",
        " z_delta =   * dpred_dz\n",
        "\n",
        " #Multiplying with the 3rd individual derivative :\n",
        " inputs = input_features.T\n",
        " weights -= lr * np.dot(inputs, z_delta)\n",
        " \n",
        " #Updating the bias weight value :\n",
        " for i in z_delta:\n",
        "    bias -= lr * i\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r71XM6cxNHAU"
      },
      "source": [
        "# Making predictions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vy2DoZvNHAU"
      },
      "source": [
        " a. A tested person is positive for the virus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EjAlN4lNHAU"
      },
      "source": [
        "#\n",
        "#Taking inputs :\n",
        "single_point = np.array([# WRITE YOUR CODE HERE])#1st step :\n",
        "result1 = np.dot(single_point, weights) + bias#2nd step :\n",
        "result2 = sigmoid(result1)\n",
        "#Print final result\n",
        "print(result2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71pYH1HNNHAU"
      },
      "source": [
        "b. A tested person is negative for the virus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61sl643VNHAV"
      },
      "source": [
        "#Taking inputs :\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "print(result2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEf-Nb_vNHAV"
      },
      "source": [
        "\n",
        "#Printing final weights and bias : \n",
        "print (weights)\n",
        "print (\"\\n\\n\")\n",
        "print (bias)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMzX4oO1NHAV"
      },
      "source": [
        "## Inference :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sppi2pHENHAV"
      },
      "source": [
        "# PART 10.2:  Neural Network using Tensorflow and Keras  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNc6ZZYkNHAW"
      },
      "source": [
        "# Introduction to Tensorflow and Keras\n",
        "\n",
        "TensorFlow is an open-source software library for machine learning in various kinds of perceptual and language understanding tasks. It is currently used for both research and production by different teams in many commercial Google products, such as speech recognition, Gmail, Google Photos, and search, many of which had previously used its predecessor DistBelief. TensorFlow was originally developed by the Google Brain team for Google's research and production purposes and later released under the Apache 2.0 open source license on November 9, 2015.\n",
        "\n",
        "TensorFlow is a low-level mathematics API, similar to Numpy. However, unlike Numpy, TensorFlow is built for deep learning. TensorFlow compiles these compute graphs into highly efficient C++/CUDA cod\n",
        "\n",
        "\n",
        "* [TensorFlow Homepage](https://www.tensorflow.org/)\n",
        "* [TensorFlow GitHib](https://github.com/tensorflow/tensorflow)\n",
        "* [TensorFlow Google Groups Support](https://groups.google.com/forum/#!forum/tensorflow)\n",
        "* [TensorFlow Google Groups Developer Discussion](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss)\n",
        "* [TensorFlow FAQ](https://www.tensorflow.org/resources/faq)\n",
        "\n",
        "\n",
        "\n",
        "## Why TensorFlow\n",
        "\n",
        "* Supported by Google\n",
        "* Works well on Windows, Linux, and Mac\n",
        "* Excellent GPU support\n",
        "* Python is an easy to learn programming language\n",
        "* Python is extremely popular in the data science community\n",
        "\n",
        "## Deep Learning Tools\n",
        "TensorFlow is not the only game in town. The biggest competitor to TensorFlow/Keras is PyTorch. Listed below are some of the deep learning toolkits actively being supported:\n",
        "\n",
        "* [TensorFlow](https://www.tensorflow.org/) Google's deep learning API.  The focus of this class, along with Keras.\n",
        "* [Keras](https://keras.io/) - Also by Google, higher level framework that allows the use of TensorFlow, MXNet and Theano interchangeably.\n",
        "* [PyTorch](https://pytorch.org/) - PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is primarily developed by Facebook's AI Research lab. \n",
        "\n",
        "Other deep learning tools:\n",
        "\n",
        "* [MXNet](https://mxnet.incubator.apache.org/) Apache foundation's deep learning API. Can be used through Keras.\n",
        "* [Torch](http://torch.ch/) is used by Google DeepMind, the Facebook AI Research Group, IBM, Yandex and the Idiap Research Institute.  It has been used for some of the most advanced deep learning projects in the world.  However, it requires the [LUA](https://en.wikipedia.org/wiki/Lua_(programming_language)) programming language.  It is very advanced, but it is not mainstream.  I have not worked with Torch (yet!).\n",
        "* [PaddlePaddle](https://github.com/baidu/Paddle) - [Baidu](http://www.baidu.com/)'s deep learning API.\n",
        "* [Deeplearning4J](http://deeplearning4j.org/) - Java based. Supports all major platforms. GPU support in Java!\n",
        "* [Computational Network Toolkit (CNTK)](https://github.com/Microsoft/CNTK) - Microsoft.  Support for Windows/Linux, command line only.  Bindings for predictions for C#/Python. GPU support.\n",
        "* [H2O](http://www.h2o.ai/) - Java based.  Supports all major platforms.  Limited support for computer vision. No GPU support.\n",
        "\n",
        "## Using TensorFlow Directly\n",
        "\n",
        "TensorFlow using Keras allows you to specify the number of hidden layers and create the neural network.  TensorFlow is a low-level mathematics API, similar to [Numpy](http://www.numpy.org/).  However, unlike Numpy, TensorFlow is built for deep learning. TensorFlow compiles these compute graphs into highly efficient C++/[CUDA](https://en.wikipedia.org/wiki/CUDA) code.\n",
        "\n",
        "### TensorFlow Linear Algebra Examples\n",
        "\n",
        "TensorFlow is a library for linear algebra.  Keras is a higher-level abstraction for neural networks that you build upon TensorFlow.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho0iQg3bNHAW"
      },
      "source": [
        "For more detail Refer  -  https://keras.io/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klh-nAYxNHAW"
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEI7o8oQNHAX"
      },
      "source": [
        "! pip install tensorflow==2.2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLjrNQ68NHAX"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# tf.VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBQHBGxeNHAX"
      },
      "source": [
        "### What version of TensorFlow do you have?\n",
        "\n",
        "TensorFlow is very new and changing rapidly.  we may use a 2.2 an above version of TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mioja-8YNHAX"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA_UAbINHAX"
      },
      "source": [
        "### Introduction to Keras\n",
        "\n",
        "[Keras](https://keras.io/) is a layer on top of Tensorflow that makes it much easier to create neural networks.  Rather than define the graphs, as you see above, you set the individual layers of the network with a much more high-level API.  Unless you are performing research into entirely new structures of deep neural networks, it is unlikely that you need to program TensorFlow directly.  \n",
        "\n",
        "**For this class, we will use usually use TensorFlow through Keras, rather than direct TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XEWi75bNHAY"
      },
      "source": [
        "import keras; print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIza7GOlNHAY"
      },
      "source": [
        "## PART 10.3: Binary Classification- A 3 layer NN from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpeg5WfkNHAY"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psjhu6MpNHAY"
      },
      "source": [
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Igp5WJNHAY"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p6QanMONHAY"
      },
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJpYTY4lNHAY"
      },
      "source": [
        "# NN model :  Input Layer: 8 neuron ; Hidden Layer H1 :  12 Neuron, Hidden Layer H2; 8 neuron, Output Layer:  01  \n",
        "\n",
        "model = Sequential()  # Empty at this stage \n",
        "\n",
        "\n",
        "# CODE  for Hidden Layer H1  \n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\n",
        "# WRITE YOUR CODE HERE for Hidden Layer H2\n",
        "\n",
        "# WRITE YOUR CODE HERE for Output Layer\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFmZgm5qNHAZ"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQUtj6KNNHAZ"
      },
      "source": [
        "model.summary() \n",
        "\n",
        "# H1: 8*12+12= 108\n",
        "# H2: 12*8+8= 104\n",
        "# Output Layer = 8+1=9\n",
        "\n",
        "# Total = 108+104+9=221\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmX_3e0zNHAZ"
      },
      "source": [
        "history = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), epochs=150, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ydn6UBVNHAZ"
      },
      "source": [
        "model.evaluate(X_train, Y_train),model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVhHboyNHAZ"
      },
      "source": [
        "predictions = model.predict_classes(X_test)\n",
        "for i in range(10):\n",
        "    print('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], Y_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKVdylNlNHAa"
      },
      "source": [
        "# val_loss\n",
        "# acc\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "# plt.plot(history.history['accuracy'])   # it will work in other version \n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laxmT9AHNHAa"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.ylim((0,2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}